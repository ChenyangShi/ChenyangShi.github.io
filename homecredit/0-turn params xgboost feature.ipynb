{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('df_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 1022)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bin_feature in ['FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "    df[bin_feature], uniques = pd.factorize(df[bin_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['FLAG_OWN_CAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['FLAG_OWN_REALTY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 1022)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, cat_cols = one_hot_encoder(df, nan_as_category=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 1141)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USELESS_COLUMNS = ['FLAG_DOCUMENT_10',\n",
    "                   'FLAG_DOCUMENT_12',\n",
    "                   'FLAG_DOCUMENT_13',\n",
    "                   'FLAG_DOCUMENT_14',\n",
    "                   'FLAG_DOCUMENT_15',\n",
    "                   'FLAG_DOCUMENT_16',\n",
    "                   'FLAG_DOCUMENT_17',\n",
    "                   'FLAG_DOCUMENT_19',\n",
    "                   'FLAG_DOCUMENT_2',\n",
    "                   'FLAG_DOCUMENT_20',\n",
    "                   'FLAG_DOCUMENT_21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df= df.drop(USELESS_COLUMNS,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 1130)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting xgb. Train shape: (307511, 1130), test shape: (48744, 1130)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df['TARGET'].notnull()]\n",
    "test_df = df[df['TARGET'].isnull()]\n",
    "print(\"Starting xgb. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 测试 取100行\n",
    "train_df=train_df.iloc[:100,:]\n",
    "test_df=test_df.iloc[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "X=train_df[feats]\n",
    "y=train_df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from bayes_opt import bayesian_optimization\n",
    "import sklearn.cross_validation as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:52: DeprecationWarning: Class GaussianProcess is deprecated; GaussianProcess was deprecated in version 0.18 and will be removed in 0.20. Use the GaussianProcessRegressor instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 01m32s | \u001b[35m   0.50000\u001b[0m | \u001b[32m             0.7674\u001b[0m | \u001b[32m            0.6418\u001b[0m | \u001b[32m   0.9690\u001b[0m | \u001b[32m    13.3932\u001b[0m | \u001b[32m            9.7846\u001b[0m | \u001b[32m     0.0025\u001b[0m | \u001b[32m      0.0025\u001b[0m | \u001b[32m     0.7896\u001b[0m | \n"
     ]
    }
   ],
   "source": [
    "def xgboostcv(max_depth,\n",
    "              gamma,\n",
    "              min_child_weight,\n",
    "              colsample_bylevel,\n",
    "              subsample,\n",
    "              colsample_bytree,\n",
    "              reg_lambda,\n",
    "              reg_alpha,\n",
    "              silent=True,\n",
    "              objective='binary:logistic',\n",
    "              learning_rate=0.02,\n",
    "              n_estimators=5000):\n",
    "    return cross_val_score(xgb.XGBClassifier(max_depth=int(max_depth),\n",
    "                                             learning_rate=learning_rate,\n",
    "                                             n_estimators=n_estimators,\n",
    "                                             colsample_bylevel=colsample_bylevel,\n",
    "                                             silent=silent,\n",
    "                                            objective=objective,\n",
    "                                            gamma=gamma,\n",
    "                                            min_child_weight=min_child_weight,\n",
    "                                            subsample=subsample,\n",
    "                                            colsample_bytree=colsample_bytree,\n",
    "                                            reg_alpha=reg_alpha,\n",
    "                                            reg_lambda=reg_lambda),\n",
    "                           X,\n",
    "                           y,\n",
    "                           'roc_auc',\n",
    "                           cv=5).mean()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    xgboostBO = bayesian_optimization.BayesianOptimization(xgboostcv,\n",
    "                                 {'gamma':(0.01,1),\n",
    "                                 'max_depth' : (4,20),\n",
    "                                 'min_child_weight' : (2,10),\n",
    "                                 'subsample' : (0.4,0.9),\n",
    "                                 'colsample_bytree' : (0.4,0.9),\n",
    "                                 'colsample_bylevel' : (0.7,1),\n",
    "                                 'reg_alpha' : (0,0.01),\n",
    "                                 'reg_lambda' : (0,0.01)})\n",
    "    xgboostBO.maximize(init_points=2, n_iter = 2)\n",
    "    print('-'*53)\n",
    "    print('Final Results')\n",
    "    print('XGBOOST: %f' % xgboostBO.res['max']['max_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.741412\tvalid-auc:0.602773\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 100 rounds.\n",
      "[100]\ttrain-auc:0.957363\tvalid-auc:0.76541\n",
      "[200]\ttrain-auc:0.985686\tvalid-auc:0.774812\n",
      "[300]\ttrain-auc:0.995787\tvalid-auc:0.781254\n",
      "[400]\ttrain-auc:0.998805\tvalid-auc:0.784253\n",
      "[500]\ttrain-auc:0.999628\tvalid-auc:0.785623\n",
      "[600]\ttrain-auc:0.99989\tvalid-auc:0.78576\n",
      "[700]\ttrain-auc:0.999974\tvalid-auc:0.785788\n",
      "Stopping. Best iteration:\n",
      "[649]\ttrain-auc:0.999944\tvalid-auc:0.785963\n",
      "\n",
      "Fold  1 AUC : 0.785963\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits= 5, shuffle=True, random_state=1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "dtest=xgb.DMatrix(test_df[feats])\n",
    "    \n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "    dtrain = xgb.DMatrix(train_df[feats].iloc[train_idx],train_df['TARGET'].iloc[train_idx])\n",
    "    dvalid = xgb.DMatrix(train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx])\n",
    "    valid_y=train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "       # xgb\n",
    "    params = {'eval_metric': 'auc',\n",
    "              'objective': 'binary:logistic',\n",
    "              'booster':'gbtree',\n",
    "              'tree_method': 'auto',\n",
    "              'nthread' : 4,\n",
    "              'eta' : 0.02,\n",
    "               'max_leaves': 40,\n",
    "              'max_depth' : 16,\n",
    "              'max_bin': 255,\n",
    "              'min_child_weight' : 4,\n",
    "              'subsample' : 0.5,\n",
    "              'colsample_bytree' : 0.5,\n",
    "              'colsample_bylevel' : 1,\n",
    "              'alpha' : 0.001,\n",
    "              'lambda' : 0.001,\n",
    "              'scale_pos_weight': 1}\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "        \n",
    "    model=xgb.train(params, dtrain, 5000, watchlist, maximize=True, early_stopping_rounds = 100, verbose_eval=100)\n",
    "    oof_preds[valid_idx] = model.predict(dvalid, ntree_limit=model.best_ntree_limit)\n",
    "    sub_preds += model.predict(dtest,ntree_limit=model.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df = pd.DataFrame(model.get_fscore().items(), columns=['feature','importance']).sort_values('importance', ascending=False)\n",
    "    fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "    del model, dtrain, dvalid, valid_y\n",
    "\n",
    "print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "test_df['TARGET'] = sub_preds\n",
    "test_df[['SK_ID_CURR', 'TARGET']].to_csv('xgb_1000feature.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "plt.figure(figsize=(8, 10))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "plt.title('XGB Features (avg over folds)')\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importance_df.to_csv('feature_importance_xgb1000features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
